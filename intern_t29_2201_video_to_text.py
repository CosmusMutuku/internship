# -*- coding: utf-8 -*-
"""intern-t29-2201-video-to-text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J2oyNX-g0sIV87WrNWCdHRDUaeENF7k2
"""



"""# **Video to Text Transcription Project**

This notebook covers the transcription of video files to text using selected models from open source AI projects.
"""

!pip install torch

"""# **Installing Dependencies**"""

!pip install pytube -q
!pip install huggingsound -q
!pip install -q transformers




import librosa
import torch
import warnings
import soundfile as sf
warnings.filterwarnings('ignore')


from pytube import YouTube


device = "cuda" if torch.cuda.is_available() else "cpu"



"""# **Importing Source Video Data**"""

!pip install boto3


import boto3

#Read S3 bucket
BUCKET_NAME = 'interns-t29-2201-meeting-recording-summarisation' # replace with your bucket name

# enter authentication credentials
s3 = boto3.resource('s3', aws_access_key_id = 'AKIA5XNJCCEVJ2HQKLAA',
                          aws_secret_access_key= 'uLm2VQXEaXDI3fcxYF1WcrUCS3z5424MjcZ8tJwt')



KEY = 'inputdatavideos/yt1s.com - Youre a bad weak lawyer  Malema to AfriForums attorney.mp4' # replace with your object key

try:
  # we are trying to download training dataset from s3 with name `my-training-data.csv`
  # to colab dir with name `training.csv`
  s3.Bucket(BUCKET_NAME).download_file(KEY, 'training.mp4')

except botocore.exceptions.ClientError as e:
  if e.response['Error']['Code'] == "404":
    print("The object does not exist.")
  else:
    raise

#Install pytube package and YouTube to aid getting YouTube videos

#Give the youtube video link to be converted and transcripted
#video_link="https://www.youtube.com/watch?v=3WrZMzqpFTc"

#Get the video
#yt=YouTube(video_link)
#yt.streams \
  #.filter(only_audio = True, file_extension = 'mp4') \
  #.first() \
  #.download(filename = 'ytaudio.mp4')

"""# **Video Conversion to Audio**"""

!pip install ffmpeg-python

conda install -c conda-forge ffmpeg

!ffmpeg

import ffmpeg

#We use FFmpeg to convert the video to audio
! ffmpeg -i ytaudio.mp4 -acodec pcm_s16le -ar 16000 ytaudio.wav

"""# **Speaker Diarization**"""

conda install -c conda-forge webrtcvad

!pip install Resemblyzer
from resemblyzer import preprocess_wav, VoiceEncoder
from pathlib import Path

#give the file path to your audio file
audio_file_path = "ytaudio.wav"
wav_fpath = Path(audio_file_path)

wav = preprocess_wav(wav_fpath)
encoder = VoiceEncoder("cpu")
_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)
print(cont_embeds.shape)

!pip3 install spectralcluster
from spectralcluster import SpectralClusterer
from spectralcluster import RefinementOptions

refinement_options = RefinementOptions(
    gaussian_blur_sigma=1,
    p_percentile=0.90)
clusterer = SpectralClusterer(
    min_clusters=2,
    max_clusters=100)

labels = clusterer.predict(cont_embeds)

def create_labelling(labels,wav_splits):
    from resemblyzer.audio import sampling_rate
    times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]
    labelling = []
    start_time = 0

    for i,time in enumerate(times):
        if i>0 and labels[i]!=labels[i-1]:
            temp = [str(labels[i-1]),start_time,time]
            labelling.append(list(temp))
            start_time = time
        if i==len(times)-1:
            temp = [str(labels[i]),start_time,time]
            labelling.append(list(temp))

    return labelling

labelling = create_labelling(labels,wav_splits)

"""**Sequential splitting of the  Audio file following timestamps obtained from Diarization.**"""

audio_chunks2 = []
l=0
for k in range(len(labelling)):
  s=labelling[k][1]
  e=labelling[k][2]
  filename = str(l)+"ytaudio.wav"
  !ffmpeg -i ytaudio.wav -ss {s} -t {e} -acodec copy {filename}
  l=l+1
  audio_chunks2.append(filename)

audio_chunks2

"""# **Transcription and post processing using the open ai whisper ASR**"""

!pip install git+https://github.com/openai/whisper.git

import whisper

model = whisper.load_model("large")

result=''
n=range(0, len(audio_chunks2))
for i in n:
  result+= model.transcribe(str(i)+'ytaudio.wav')['text']

result

"""# **Saving the transcribed text to S3 Bucket using Boto3 resource**"""

f = open("s3_transcription.txt", "w")
f.write(result)
f.close()

#Creating Session With Boto3.
session = boto3.Session(
aws_access_key_id='AKIA5XNJCCEVDYKIB4GJ',
aws_secret_access_key='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'
)

#Creating S3 Resource From the Session.
s3 = session.resource('s3')

result = s3.Bucket('interns-t21-2201-meeting-recording-summarisation').upload_file('/content/s3_transcription.txt','team-29-output.txt')

print(result)